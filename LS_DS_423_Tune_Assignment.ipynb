{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_433_Tune_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Train Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Using your baseline model from yesterday, hyperparameter tune it and report on your highest validation accuracy. Your singular goal today is to achieve the highest accuracy possible.\n",
        "\n",
        "*Don't forgot to switch to GPU on Colab!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptJ2b3wk62Ud",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameters to Tune\n",
        "\n",
        "At a minimum, tune each of these hyperparameters using any strategy we discussed during lecture today: \n",
        "- Optimizer\n",
        "- Learning Rate\n",
        "- Activiation Function\n",
        "  - At least 1 subparameter within the Relu activation function\n",
        "- Number of Neurons in Hidden Layers\n",
        "- Number of Hidden Layers\n",
        "- Weight Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXjs7Hk71Hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_quickdraw10(path):\n",
        "  data = np.load('quickdraw10.npz')\n",
        "  X = data['arr_0']\n",
        "  y = data['arr_1']\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  \n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test = load_quickdraw10(r'U4W2\\module3-Tune')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 3.1404 - accuracy: 0.2871\nEpoch 2/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 1.6579 - accuracy: 0.3946\nEpoch 3/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 1.5124 - accuracy: 0.4475\nEpoch 4/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 1.3623 - accuracy: 0.5146\nEpoch 5/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 1.2323 - accuracy: 0.5624\nEpoch 6/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 1.1281 - accuracy: 0.6137\nEpoch 7/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 1.0466 - accuracy: 0.6510\nEpoch 8/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 1.0036 - accuracy: 0.6679\nEpoch 9/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9785 - accuracy: 0.6791\nEpoch 10/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9708 - accuracy: 0.6785\nEpoch 11/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9637 - accuracy: 0.6856\nEpoch 12/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9534 - accuracy: 0.6884\nEpoch 13/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9516 - accuracy: 0.6907\nEpoch 14/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9466 - accuracy: 0.6908\nEpoch 15/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9444 - accuracy: 0.6907\nEpoch 16/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9409 - accuracy: 0.6931\nEpoch 17/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9385 - accuracy: 0.6953\nEpoch 18/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9358 - accuracy: 0.6951\nEpoch 19/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9344 - accuracy: 0.6946\nEpoch 20/20\n1047/1047 [==============================] - 1s 1ms/step - loss: 0.9319 - accuracy: 0.6966\nBest: 0.7110149264335632 using {&#39;batch_size&#39;: 64, &#39;epochs&#39;: 20, &#39;units&#39;: 32}\nMeans: 0.6509402990341187, Stdev: 0.06733456595189902 with: {&#39;batch_size&#39;: 32, &#39;epochs&#39;: 20, &#39;units&#39;: 32}\nMeans: 0.7110149264335632, Stdev: 0.017163517261421013 with: {&#39;batch_size&#39;: 64, &#39;epochs&#39;: 20, &#39;units&#39;: 32}\nMeans: 0.5564776062965393, Stdev: 0.03144147089073887 with: {&#39;batch_size&#39;: 512, &#39;epochs&#39;: 20, &#39;units&#39;: 32}\n"
        }
      ],
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "def create_model(units=32):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units, input_dim=784, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
        "\n",
        "param_grid = {'batch_size': [32,64,512],\n",
        "              'epochs': [20],\n",
        "              'units':[32],\n",
        "              }\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKbr1gRg9BXs",
        "colab_type": "text"
      },
      "source": [
        "### Stretch Goals\n",
        "- Implement Bayesian Hyper-parameter Optimization\n",
        "- Select a new dataset and apply a neural network to it.\n",
        "- Use a cloud base experiment tracking framework such as weights and biases\n",
        "- Research potential architecture ideas for this problem. Try Lenet-10 for example. "
      ]
    }
  ]
}